{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive most distinguishing words per character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import glob\n",
    "import codecs\n",
    "import re\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from google.cloud import language\n",
    "\n",
    "WORKING_DIRECTORY = \"/Users/emersonsjsu/GitHub/EarlGrey\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load words from scripts into wordcount dict\n",
    "FIRST_EPISODE_OFFSET = 101\n",
    "LAST_EPISODE_IN_SEASON = {25: 1, 47: 2, 73: 3, 99: 4, 125: 5, 151: 6, 176: 7}\n",
    "regex = re.compile('[^a-zA-Z ]')\n",
    "\n",
    "\n",
    "def get_season(episode_no):\n",
    "    return LAST_EPISODE_IN_SEASON.get(episode_no, 0)\n",
    "\n",
    "\n",
    "def sanitize_name(name_line):\n",
    "    name = name_line.strip()  # Voice overs count as same character\n",
    "    if name.endswith('V.O.'):\n",
    "        name = name[:-5]\n",
    "    # Strip parentheticals from name\n",
    "    if name.find('(') != -1:\n",
    "        name = name[:name.find('(')]\n",
    "    # Strip 'S VOICE from name\n",
    "    if name.endswith('\\'S VOICE'):\n",
    "        name = name[:-8]\n",
    "    # Strip 'S COM VOICE from name\n",
    "    if name.endswith('\\'S COM VOICE'):\n",
    "        name = name[:-12]\n",
    "    return name.strip()\n",
    "\n",
    "\n",
    "# counters_dict expects {char: (counter_obj, [s1count,s2count, ..., s7count])}\n",
    "def process_script(file_path, counters_dict):\n",
    "    current_file = codecs.open(file_path, \"r\", encoding='utf-8', errors=\"ignore\")\n",
    "    episode_no = int(current_file.name[current_file.name.rfind('/') + 1:-4]) - FIRST_EPISODE_OFFSET\n",
    "    is_dialogue = False\n",
    "    character_name = \"\"\n",
    "    lines = current_file.readlines()\n",
    "    for line in lines:\n",
    "        # Character dialogue has ended, reset current character\n",
    "        if line.strip() == '':\n",
    "            is_dialogue = False\n",
    "        # All names are preceded by exactly 5 tabs\n",
    "        elif line[:5] == '\\t\\t\\t\\t\\t' and line[5:6] != '\\t' and not line.strip().startswith('('):\n",
    "            # We have found a name! Update current name\n",
    "            character_name = sanitize_name(line)\n",
    "            is_dialogue = True\n",
    "        # If we are still looking at a character's dialogue\n",
    "        elif is_dialogue:\n",
    "            # Update character's counter object\n",
    "            counters_dict[character_name][0].update(regex.sub('', line).lower().split())\n",
    "    current_file.close()\n",
    "\n",
    "    # Check if we are end of a season\n",
    "    season_no = get_season(episode_no)\n",
    "    if season_no:\n",
    "        # Update wc per season for each character in counters_dict\n",
    "        for v in counters_dict.itervalues():\n",
    "            # Set season wc for every character. Subtract sum of previous values because counter_obj\n",
    "            # keeps cumulative word count\n",
    "            v[1][season_no - 1] = sum(v[0].values()) - sum(v[1])\n",
    "\n",
    "\n",
    "# character_wc_dict schema is {char: (counter_obj, [s1count,s2count, ..., s7count])}\n",
    "character_wc_dict = defaultdict(lambda: (Counter(), [0] * 7))\n",
    "# for full_path in sorted(glob.glob(WORKING_DIRECTORY+'/scripts/148.txt')):  # Only read one file for debug purposes\n",
    "for full_path in sorted(glob.glob(WORKING_DIRECTORY + '/clean_scripts/*.txt')):\n",
    "    process_script(full_path, character_wc_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are Picard's top 10 words and counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'the', 6768),\n (u'to', 6469),\n (u'you', 4236),\n (u'i', 3401),\n (u'a', 3207),\n (u'of', 2943),\n (u'is', 2215),\n (u'it', 2084),\n (u'and', 2049),\n (u'that', 1966)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_wc_dict['PICARD'][0].most_common(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many words does Worf say in season 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5159"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_wc_dict['WORF'][1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.6 s, sys: 507 ms, total: 24.1 s\nWall time: 24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add all character's word counts to find count of every word over all seasons, regardless of character\n",
    "universal_wc = reduce((lambda x, y: x + y), map(lambda x: x[0], character_wc_dict.itervalues()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times is the word 'Captain' said over all 7 seasons of Star Trek: TNG?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3888"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_wc['captain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(167521, u'PICARD'),\n (90119, u'DATA'),\n (80704, u'RIKER'),\n (59431, u'GEORDI'),\n (46019, u'BEVERLY'),\n (40324, u'TROI'),\n (37178, u'WORF'),\n (14631, u'WESLEY')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract most talkative 8 characters\n",
    "char_total_wc = []\n",
    "for k, v in character_wc_dict.iteritems():\n",
    "    tup = sum(v[1]), k\n",
    "    char_total_wc.append(tup)\n",
    "main_character_wc = nlargest(8, char_total_wc, lambda x: x[0])\n",
    "main_characters = [x[1] for x in main_character_wc]\n",
    "main_character_wc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most distinguishing words of main characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PICARD\n['number', 'mister', 'captains', 'log', 'stardate', 'supplemental', 'to', 'the', 'data', 'admiral']\nDATA\n['however', 'approximately', 'appears', 'correct', 'translating', 'am', 'sir', 'appear', 'lal', 'is']\nRIKER\n['soren', 'rice', 'minuet', 'strap', 'decompress', 'william', 'yuta', 'kazago', 'knockout', 'ramistat']\nGEORDI\n['reg', 'commodore', 'shipley', 'visors', 'yeah', 'bochra', 'leah', 'visor', 'logan', 'boobytrap']\nBEVERLY\n['ccs', 'nana', 'cortical', 'chilton', 'alyssa', 'stimulator', 'alissa', 'inoprovaline', 'dizziness', 'tissue']\nTROI\n['mother', 'ian', 'overbearing', 'repress', 'sensing', 'mmmhmm', 'ceramics', 'chandra', 'izmadi', 'lifeforce']\nWORF\n['hailed', 'uncloaking', 'alexander', 'kahless', 'incoming', 'battelh', 'adoptive', 'torva', 'luk', 'heghbat']\nWESLEY\n['mom', 'davies', 'repulser', 'activator', 'icospectrogram', 'custodian', 'rosseau', 'prixus', 'alans', 'sentrys']\n"
     ]
    }
   ],
   "source": [
    "anyone_speaks = sum([x[0] for x in char_total_wc])\n",
    "for person in main_characters:\n",
    "    counter = character_wc_dict[person][0]\n",
    "    person_speaks = [wc[0] for wc in main_character_wc if wc[1] == person][0]\n",
    "    defining_wc = {}\n",
    "    for word, count in counter.iteritems():\n",
    "        defining_wc[word] = (count ** 1.3)/person_speaks / (universal_wc[word]/anyone_speaks)\n",
    "    print(person)\n",
    "    top_n = nlargest(10, defining_wc.iteritems(), lambda x: x[1])\n",
    "    print([str(x[0]) for x in top_n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most distinguishing words of main characters compared to other main characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PICARD\n['number', 'mister', 'captains', 'to', 'you', 'log', 'the', 'stardate']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nDATA\n['am', 'approximately', 'however', 'correct', 'is', 'sir', 'appears', 'the']\nRIKER\n['william', 'yuta', 'soren', 'to', 'minuet', 'kazago', 'rice', 'the']\nGEORDI\n['yeah', 'hey', 'reg', 'leah', 'okay', 'gonna', 'guy', 'bochra']\nBEVERLY\n['ccs', 'nurse', 'tissue', 'nana', 'stimulator', 'symptoms', 'cerebral', 'dizziness']\nTROI\n['mother', 'isabella', 'clara', 'shiar', 'tal', 'nvek', 'hedril', 'ian']\nWORF\n['warrior', 'kahless', 'alexander', 'hailed', 'warriors', 'molor', 'koroth', 'dishonor']\nWESLEY\n['mom', 'custodian', 'nick', 'mordock', 'davies', 'josh', 'repulser', 'activator']\n"
     ]
    }
   ],
   "source": [
    "any_main_character_speaks = sum([x[0] for x in main_character_wc])\n",
    "main_characters_counter = Counter()\n",
    "for person in main_characters:\n",
    "    main_characters_counter.update(character_wc_dict[person][0])\n",
    "for person in main_characters:\n",
    "    counter = character_wc_dict[person][0]\n",
    "    person_speaks = [wc[0] for wc in main_character_wc if wc[1] == person][0]\n",
    "    defining_wc = {}\n",
    "    for word, count in counter.iteritems():\n",
    "        defining_wc[word] = (count ** 1.3)/person_speaks / (main_characters_counter[word]/any_main_character_speaks)\n",
    "    print(person)\n",
    "    top_n = nlargest(8, defining_wc.iteritems(), lambda x: x[1])\n",
    "    print([str(x[0]) for x in top_n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize generated information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot character's total words per season\n",
    "for person in main_characters:\n",
    "    box_fig = plt.figure('%s words over seasons' % person)\n",
    "    plt.bar(range(1, 8), character_wc_dict[person][1])\n",
    "    plt.xlabel('Season')\n",
    "    plt.ylabel('Number of words said')\n",
    "    plt.title('%s\\'s words said over the 7 seasons of TNG' % person)\n",
    "    box_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total words per season\n",
    "wc_per_season = reduce(lambda x, y: [sum(pair) for pair in zip(x,y)], map(lambda x: x[1], character_wc_dict.itervalues()))\n",
    "plt.bar(range(1,8), wc_per_season)\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Number of words said')\n",
    "plt.title('Total words said over the 7 seasons of TNG')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('wc_per_char')\n",
    "plt.bar(range(len(main_character_wc)), [x[0] for x in main_character_wc])\n",
    "plt.xlabel('Character')\n",
    "plt.ylabel('Number of words said')\n",
    "plt.xticks(range(len(main_character_wc)), [x[1] for x in main_character_wc])\n",
    "plt.xticks(rotation=70)\n",
    "plt.title('Words said per character')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = ['#FF9900', '#CC99CC', '#9999CC', '#CC6666', '#FFCC99',\n",
    "          '#9999FF', '#FF9966', '#CC6699']\n",
    "ALPHA = 100\n",
    "for idx, wc_tuple in enumerate(main_character_wc):\n",
    "    fig = plt.figure(figsize=(.75, 2))\n",
    "    ax = fig.add_subplot(111)\n",
    "    count = wc_tuple[0]\n",
    "    character = wc_tuple[1]\n",
    "    ax.bar(0, count, color=COLORS[idx % len(COLORS)])\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.set_ylim(0, max([x[0] for x in main_character_wc]))\n",
    "    ax.set_xticks([], False)\n",
    "    ax.set_yticks([], False)\n",
    "    plt.show()\n",
    "    fig.savefig(character+'_total', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot character's total words per season\n",
    "for idx, person in enumerate(main_characters):\n",
    "    fig = plt.figure(figsize=(9, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.bar(range(1, 8), character_wc_dict[person][1], color=COLORS[idx % len(COLORS)])\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.set_xticks([], False)\n",
    "    ax.set_yticks([], False)\n",
    "    plt.show()\n",
    "    fig.savefig(person+'_by_season', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(range(len(main_character_wc)), [x[0] for x in main_character_wc], color=COLORS)\n",
    "plt.yticks(np.arange(0, 170001, 170000/2))\n",
    "ax.tick_params(axis='y', colors='#FF9900', labelleft=False)\n",
    "ax.set_xticks([], False)\n",
    "#ax.set_yticks([], False)\n",
    "ax.xaxis.set_tick_params(width=3)\n",
    "ax.yaxis.set_tick_params(width=3)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for axis in ['bottom', 'left']:\n",
    "    ax.spines[axis].set_linewidth(3)\n",
    "    ax.spines[axis].set_color('#FF9900')\n",
    "plt.show()\n",
    "fig.savefig('words_per_character', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total words per season\n",
    "wc_per_season = reduce(lambda x, y: [sum(pair) for pair in zip(x,y)], map(lambda x: x[1], character_wc_dict.itervalues()))\n",
    "fig = plt.figure(figsize=(4.5, 1.5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(range(1,8), wc_per_season, color=['#FF9900'])\n",
    "ax.tick_params(axis='x', colors='#FF9900', labelbottom=False)\n",
    "ax.set_xticks([], True)\n",
    "ax.set_yticks([], False)\n",
    "ax.xaxis.set_tick_params(width=3)\n",
    "ax.yaxis.set_tick_params(width=3)\n",
    "ax.spines['bottom'].set_linewidth(3)\n",
    "ax.spines['bottom'].set_color('#FF9900')\n",
    "for axis in ['right', 'top', 'left']:\n",
    "    ax.spines[axis].set_visible(False)\n",
    "plt.show()\n",
    "fig.savefig('words_per_season', transparent=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
